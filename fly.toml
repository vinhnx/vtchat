# Production fly.toml
app = 'vtchat'
primary_region = 'sin'

[build]
  # Enable build target for optimized caching
  build-target = "runner"
  [build.args]
    NODE_ENV = "production"

[env]
  NODE_ENV = 'production'
  BASE_URL = 'https://vtchat.io.vn'
  BETTER_AUTH_URL = 'https://vtchat.io.vn'
  NEXT_PUBLIC_BASE_URL = 'https://vtchat.io.vn'
  NEXT_PUBLIC_APP_URL = 'https://vtchat.io.vn'
  NEXT_PUBLIC_COMMON_URL = 'https://vtchat.io.vn'
  NEXT_PUBLIC_BETTER_AUTH_URL = 'https://vtchat.io.vn'
  CREEM_ENVIRONMENT = 'production'
  BETTER_AUTH_ENV = 'production'
  # Next.js optimizations
  NEXT_TELEMETRY_DISABLED = '1'
  PORT = '3000'
  NODE_OPTIONS = '--max-old-space-size=512'
  # AI SDK optimizations
  AI_SDK_TELEMETRY_DISABLED = '1'
  VERCEL_ANALYTICS_DISABLED = '1'

# https://fly.io/docs/blueprints/resilient-apps-multiple-machines/
[http_service]
  internal_port = 3000
  force_https = true

  # https://fly.io/docs/launch/autostop-autostart/#configure-autostop-autostart
  auto_stop_machines = "stop" # Fly Proxy stops Machines based on traffic
  auto_start_machines = true # Fly Proxy starts Machines based on traffic
  min_machines_running = 0 # No. of Machines to keep running in primary region

  processes = ['app']
  [http_service.concurrency]
    type = "requests"
    soft_limit = 50     # Optimized for AI streaming responses
    hard_limit = 100    # Prevent AI timeout issues

# HTTP health check for /api/health endpoint
[[http_service.checks]]
  grace_period = "30s"      # Increased for AI app startup time
  interval = "30s"          # More frequent checks
  method = "GET"
  timeout = "15s"           # Longer timeout for AI responses
  path = "/api/health"
  headers = { "User-Agent" = "Fly-Health-Check" }

# TCP health check for port connectivity
[[http_service.checks]]
  type = "tcp"
  grace_period = "5s"
  interval = "15s"
  timeout = "2s"

[[vm]]
  memory = '512mb'    # Start small for <10 users
  cpu_kind = 'shared'
  cpus = 1